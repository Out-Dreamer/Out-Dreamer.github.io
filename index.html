<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Improve Cross-Architecture Generalization on Dataset Distillation</title>
<link href="./assets/style.css" rel="stylesheet">
<script type="text/javascript" src="./assets/jquery.mlens-1.0.min.js"></script> 
<script type="text/javascript" src="./assets/jquery.js"></script>
</head>

<body>
<div class="content">
  <h1><strong>OutDreamer: Video Outpainting with a Diffusion Transformer</strong></h1>
  <p id="authors"></span>author1 author2 author3<br>
    <br>
  <span style="font-size: 24px">Company/School
  </span></p>
  <br>
  <font size="+2">
        <p style="text-align: center;">
          <a href="https://github.com/zhongzero/OutDreamer-test" target="_blank">[Code]</a> &nbsp;&nbsp;&nbsp;&nbsp;
  </font>
</div>

<div class="content">
  <div style="text-align: center;">
    <video id="myVideo" width="800" height="600" controls style="max-width: 100%;">
      <source src="https://github.com/user-attachments/assets/1de99952-eb16-4e9f-9703-12e962138e10" type="video/mp4">
      Your browser does not support the video tag.
    </video>
  </div>
</div>



<div class="content">
  <h2 style="text-align:center;">Abstract</h2>
  <a name="fig1">
  <br>
  <img class="summary-img" src="./assets/overview.jpg" style="width:85%;" height="475"> <br>
  </a>
  <p>Video outpainting is a challenging task that generates new video content by extending beyond the boundaries of an original input video, requiring both temporal and spatial consistency. Many state-of-the-art methods use latent diffusion models with U-Net backbones but still struggle to achieve high quality and adaptability in generated content. Diffusion transformers (DiTs) have emerged as a promising alternative because of their better scalability. However, commonly used control methods for video conditions in U-Net backbones, such as ControlNet, are rarely compatible with DiTs. To address this, we introduce OutDreamer, a DiT-based video outpainting framework with two main components: an efficient video control branch and a conditional outpainting branch. The efficient video control branch uses a light-weight module to extract guidance information, which is injected into the denoising model after the first DiT block, significantly improving training efficiency. The conditional outpainting branch receives condition information effectively, and employs a cross-video-clip refiner to iteratively generate missing content for long video outpainting, ensuring temporal consistency across video clips. Additionally, a color alignment loss is proposed to maintain color consistency both within and between frames. Extensive evaluations show that our zero-shot OutDreamer outperforms state-of-the-art zero-shot methods on widely recognized benchmarks.</p>
</div>

<div class="content">
  <h2 style="text-align:center;">Results</h2>
  <video class="vid_generation" id="i11" autoplay controls muted loop height=300>
    <source src="./assets/mp4-libx264/example-1-input.mp4" type="video/mp4">
  </video>
</div>

</body>
</html>
